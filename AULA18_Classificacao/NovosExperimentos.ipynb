{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1869aa44",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import csv\n",
    "import ast\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38b4fcb9",
   "metadata": {},
   "source": [
    "## Leitura do arquivo com dados de treino"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "36551df6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('featuresTrain.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "53b327ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df\n",
    "X = X.values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e08eb6d",
   "metadata": {},
   "source": [
    "## Leitura do arquivo com os rótulos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "9fc677a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('labelsTrain.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f517f632",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df\n",
    "y = y['0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "0c4be661",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56c416c6",
   "metadata": {},
   "source": [
    "## Fazer split dos dados com 70% para treino e 30% só para testes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "55962f0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "4cbbdb42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3404, 51)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "f9f195a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4214    1.0\n",
       "2892    1.0\n",
       "2476    1.0\n",
       "3065    1.0\n",
       "4160    1.0\n",
       "       ... \n",
       "4426    1.0\n",
       "466     0.0\n",
       "3092    1.0\n",
       "3772    1.0\n",
       "860     0.0\n",
       "Name: 0, Length: 3404, dtype: float64"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "172b5757",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2.186e+03, 4.000e+00, 8.000e+00, ..., 1.100e+01, 5.000e+00,\n",
       "        8.000e+00],\n",
       "       [3.353e+03, 8.000e+00, 3.000e+00, ..., 6.000e+00, 2.000e+00,\n",
       "        6.000e+00],\n",
       "       [2.651e+03, 1.200e+01, 3.000e+00, ..., 4.000e+00, 3.000e+00,\n",
       "        8.000e+00],\n",
       "       ...,\n",
       "       [1.743e+03, 3.000e+00, 6.000e+00, ..., 5.000e+00, 3.000e+00,\n",
       "        1.000e+01],\n",
       "       [2.436e+03, 7.000e+00, 5.000e+00, ..., 2.000e+00, 4.000e+00,\n",
       "        8.000e+00],\n",
       "       [2.229e+03, 7.000e+00, 1.700e+01, ..., 8.000e+00, 3.000e+00,\n",
       "        5.000e+00]])"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "72628ff7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2186    0.0\n",
       "3353    1.0\n",
       "2651    1.0\n",
       "2104    0.0\n",
       "4492    1.0\n",
       "       ... \n",
       "498     0.0\n",
       "4229    1.0\n",
       "1743    0.0\n",
       "2436    1.0\n",
       "2229    0.0\n",
       "Name: 0, Length: 1460, dtype: float64"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "f30ebeb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8e26cd8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "b7342efb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.model_selection import KFold,StratifiedKFold\n",
    "from sklearn.metrics import precision_score #precision\n",
    "from sklearn.metrics import recall_score # revocacao\n",
    "from sklearn.metrics import accuracy_score #acuracia\n",
    "from sklearn.metrics import f1_score #f1-score\n",
    "from sklearn.metrics import confusion_matrix, classification_report # matriz de confusão \n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.model_selection import cross_validate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82cd2446",
   "metadata": {},
   "source": [
    "## Definição do treino para um algoritmo de SVM. \n",
    "\n",
    "* K-fold = 5, stratified (), sendo este objeto de validação cruzada é uma variação do KFold que retorna folds estratificados. s folds são feitos preservando a porcentagem de amostras para cada classe.\n",
    "* Algoritmo SVM, sendo SVC()\n",
    "* Divisão dos arquivos de treino/validação pelo k-fold\n",
    "* Predição dos dados\n",
    "* Cálculo de métricas estatísticas. Há várias métricas, comum é: acurácia, precisão e recall.\n",
    "* 10 execuções de treino.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "b1e47e59",
   "metadata": {},
   "outputs": [],
   "source": [
    "execucoes = []\n",
    "kf = StratifiedKFold(n_splits=5, random_state=None, shuffle=False)\n",
    "k = 1\n",
    "i = 0\n",
    "for i in range(10):\n",
    "    k = 1\n",
    "    for indices_treino, indices_teste in kf.split(X_train, y_train):\n",
    "        k+=1\n",
    "        clf = SVC()\n",
    "        X_Ttrain, X_Ttest = X[indices_treino], X[indices_teste]\n",
    "        y_Ttrain, y_Ttest = y[indices_treino], y[indices_teste]\n",
    "        clf.fit(X_Ttrain, y_Ttrain)\n",
    "        predicao_treino = clf.predict(X_Ttest)\n",
    "    # métricas de validacao\n",
    "        precision = precision_score(y_Ttest,predicao_treino, average='binary', zero_division=0)*100 # Calculando a precisao\n",
    "        revocacao =recall_score(y_Ttest, predicao_treino, average='binary', zero_division=0)*100 # Calcula a revocacao\n",
    "        acc = accuracy_score(y_Ttest, predicao_treino)*100   # acuracia\n",
    "        cm = confusion_matrix(y_Ttest, predicao_treino)\n",
    "    \n",
    "        execucoes.append({\n",
    "                        'Kfold':k,\n",
    "                        'acuracia':acc,\n",
    "                        'precisao':precision,\n",
    "                        'revocacao':revocacao,\n",
    "                        'cm': cm\n",
    "                        })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "4fd9a4cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(execucoes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "7160fec8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Kfold</th>\n",
       "      <th>acuracia</th>\n",
       "      <th>precisao</th>\n",
       "      <th>revocacao</th>\n",
       "      <th>cm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[[681]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[[681]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[[681]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>95.007342</td>\n",
       "      <td>89.570552</td>\n",
       "      <td>100.0</td>\n",
       "      <td>[[355, 34], [0, 292]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.0</td>\n",
       "      <td>[[680]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[[681]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[[681]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>4</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[[681]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>5</td>\n",
       "      <td>95.007342</td>\n",
       "      <td>89.570552</td>\n",
       "      <td>100.0</td>\n",
       "      <td>[[355, 34], [0, 292]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>6</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.0</td>\n",
       "      <td>[[680]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[[681]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>3</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[[681]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>4</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[[681]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>5</td>\n",
       "      <td>95.007342</td>\n",
       "      <td>89.570552</td>\n",
       "      <td>100.0</td>\n",
       "      <td>[[355, 34], [0, 292]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>6</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.0</td>\n",
       "      <td>[[680]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[[681]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>3</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[[681]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>4</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[[681]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>5</td>\n",
       "      <td>95.007342</td>\n",
       "      <td>89.570552</td>\n",
       "      <td>100.0</td>\n",
       "      <td>[[355, 34], [0, 292]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>6</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.0</td>\n",
       "      <td>[[680]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[[681]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>3</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[[681]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>4</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[[681]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>5</td>\n",
       "      <td>95.007342</td>\n",
       "      <td>89.570552</td>\n",
       "      <td>100.0</td>\n",
       "      <td>[[355, 34], [0, 292]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>6</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.0</td>\n",
       "      <td>[[680]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>2</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[[681]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>3</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[[681]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>4</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[[681]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>5</td>\n",
       "      <td>95.007342</td>\n",
       "      <td>89.570552</td>\n",
       "      <td>100.0</td>\n",
       "      <td>[[355, 34], [0, 292]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>6</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.0</td>\n",
       "      <td>[[680]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>2</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[[681]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>3</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[[681]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>4</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[[681]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>5</td>\n",
       "      <td>95.007342</td>\n",
       "      <td>89.570552</td>\n",
       "      <td>100.0</td>\n",
       "      <td>[[355, 34], [0, 292]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>6</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.0</td>\n",
       "      <td>[[680]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>2</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[[681]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>3</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[[681]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>4</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[[681]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>5</td>\n",
       "      <td>95.007342</td>\n",
       "      <td>89.570552</td>\n",
       "      <td>100.0</td>\n",
       "      <td>[[355, 34], [0, 292]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>6</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.0</td>\n",
       "      <td>[[680]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>2</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[[681]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>3</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[[681]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>4</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[[681]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>5</td>\n",
       "      <td>95.007342</td>\n",
       "      <td>89.570552</td>\n",
       "      <td>100.0</td>\n",
       "      <td>[[355, 34], [0, 292]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>6</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.0</td>\n",
       "      <td>[[680]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>2</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[[681]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>3</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[[681]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>4</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[[681]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>5</td>\n",
       "      <td>95.007342</td>\n",
       "      <td>89.570552</td>\n",
       "      <td>100.0</td>\n",
       "      <td>[[355, 34], [0, 292]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>6</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.0</td>\n",
       "      <td>[[680]]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Kfold    acuracia    precisao  revocacao                     cm\n",
       "0       2  100.000000    0.000000        0.0                [[681]]\n",
       "1       3  100.000000    0.000000        0.0                [[681]]\n",
       "2       4  100.000000    0.000000        0.0                [[681]]\n",
       "3       5   95.007342   89.570552      100.0  [[355, 34], [0, 292]]\n",
       "4       6  100.000000  100.000000      100.0                [[680]]\n",
       "5       2  100.000000    0.000000        0.0                [[681]]\n",
       "6       3  100.000000    0.000000        0.0                [[681]]\n",
       "7       4  100.000000    0.000000        0.0                [[681]]\n",
       "8       5   95.007342   89.570552      100.0  [[355, 34], [0, 292]]\n",
       "9       6  100.000000  100.000000      100.0                [[680]]\n",
       "10      2  100.000000    0.000000        0.0                [[681]]\n",
       "11      3  100.000000    0.000000        0.0                [[681]]\n",
       "12      4  100.000000    0.000000        0.0                [[681]]\n",
       "13      5   95.007342   89.570552      100.0  [[355, 34], [0, 292]]\n",
       "14      6  100.000000  100.000000      100.0                [[680]]\n",
       "15      2  100.000000    0.000000        0.0                [[681]]\n",
       "16      3  100.000000    0.000000        0.0                [[681]]\n",
       "17      4  100.000000    0.000000        0.0                [[681]]\n",
       "18      5   95.007342   89.570552      100.0  [[355, 34], [0, 292]]\n",
       "19      6  100.000000  100.000000      100.0                [[680]]\n",
       "20      2  100.000000    0.000000        0.0                [[681]]\n",
       "21      3  100.000000    0.000000        0.0                [[681]]\n",
       "22      4  100.000000    0.000000        0.0                [[681]]\n",
       "23      5   95.007342   89.570552      100.0  [[355, 34], [0, 292]]\n",
       "24      6  100.000000  100.000000      100.0                [[680]]\n",
       "25      2  100.000000    0.000000        0.0                [[681]]\n",
       "26      3  100.000000    0.000000        0.0                [[681]]\n",
       "27      4  100.000000    0.000000        0.0                [[681]]\n",
       "28      5   95.007342   89.570552      100.0  [[355, 34], [0, 292]]\n",
       "29      6  100.000000  100.000000      100.0                [[680]]\n",
       "30      2  100.000000    0.000000        0.0                [[681]]\n",
       "31      3  100.000000    0.000000        0.0                [[681]]\n",
       "32      4  100.000000    0.000000        0.0                [[681]]\n",
       "33      5   95.007342   89.570552      100.0  [[355, 34], [0, 292]]\n",
       "34      6  100.000000  100.000000      100.0                [[680]]\n",
       "35      2  100.000000    0.000000        0.0                [[681]]\n",
       "36      3  100.000000    0.000000        0.0                [[681]]\n",
       "37      4  100.000000    0.000000        0.0                [[681]]\n",
       "38      5   95.007342   89.570552      100.0  [[355, 34], [0, 292]]\n",
       "39      6  100.000000  100.000000      100.0                [[680]]\n",
       "40      2  100.000000    0.000000        0.0                [[681]]\n",
       "41      3  100.000000    0.000000        0.0                [[681]]\n",
       "42      4  100.000000    0.000000        0.0                [[681]]\n",
       "43      5   95.007342   89.570552      100.0  [[355, 34], [0, 292]]\n",
       "44      6  100.000000  100.000000      100.0                [[680]]\n",
       "45      2  100.000000    0.000000        0.0                [[681]]\n",
       "46      3  100.000000    0.000000        0.0                [[681]]\n",
       "47      4  100.000000    0.000000        0.0                [[681]]\n",
       "48      5   95.007342   89.570552      100.0  [[355, 34], [0, 292]]\n",
       "49      6  100.000000  100.000000      100.0                [[680]]"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "0aca8332",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>acuracia</th>\n",
       "      <th>precisao</th>\n",
       "      <th>revocacao</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>95.007342</td>\n",
       "      <td>89.570552</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>95.007342</td>\n",
       "      <td>89.570552</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>95.007342</td>\n",
       "      <td>89.570552</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>95.007342</td>\n",
       "      <td>89.570552</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>95.007342</td>\n",
       "      <td>89.570552</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>95.007342</td>\n",
       "      <td>89.570552</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>95.007342</td>\n",
       "      <td>89.570552</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>95.007342</td>\n",
       "      <td>89.570552</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>95.007342</td>\n",
       "      <td>89.570552</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>95.007342</td>\n",
       "      <td>89.570552</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     acuracia   precisao  revocacao\n",
       "3   95.007342  89.570552      100.0\n",
       "8   95.007342  89.570552      100.0\n",
       "13  95.007342  89.570552      100.0\n",
       "18  95.007342  89.570552      100.0\n",
       "23  95.007342  89.570552      100.0\n",
       "28  95.007342  89.570552      100.0\n",
       "33  95.007342  89.570552      100.0\n",
       "38  95.007342  89.570552      100.0\n",
       "43  95.007342  89.570552      100.0\n",
       "48  95.007342  89.570552      100.0"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[['acuracia', 'precisao', 'revocacao']].loc[df['Kfold']==5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63e03d48",
   "metadata": {},
   "source": [
    "## Podemos criar modelos auxiliares de treino, bem como um df somente com os nomes dos modelos de algoritmos. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "f6ad0a78",
   "metadata": {},
   "outputs": [],
   "source": [
    "## class suport\n",
    "## Class axiliar para ajudar no modelos de machine learn\n",
    "class ModeloAuxiliar(object):\n",
    "    def __init__(self, clf, seed=123, params=None):\n",
    "        if params:\n",
    "            params['random_state'] = seed\n",
    "            self.clf = clf(**params)\n",
    "        else:\n",
    "            self.clf = clf()\n",
    "    def predict(self, x):\n",
    "        return self.clf.predict(x)\n",
    "    \n",
    "    def fit(self,x,y):\n",
    "        return self.clf.fit(x,y)\n",
    "    \n",
    "    def feature_importances(self,x,y):\n",
    "        return self.clf.fit(x,y).feature_importances_\n",
    "    \n",
    "    def score(self,x,y):\n",
    "        return self.clf.score(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "c054c10a",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelos = [{'nome': 'Dtree',\n",
    "            'modelo': DecisionTreeClassifier},\n",
    "            {'nome': 'Knn',\n",
    "             'modelo':KNeighborsClassifier},\n",
    "             {'nome': 'Rfrorest',\n",
    "             'modelo':RandomForestClassifier},\n",
    "             {'nome':'SGDClassifier', 'modelo':SGDClassifier}, \n",
    "             {'nome':'SVC', 'modelo':SVC},\n",
    "            {'nome':'LinearSVC', 'modelo':LinearSVC}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "9a44ef47",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|█████████████████████████████████████▌       | 5/6 [00:33<00:06,  6.55s/it]/home/fabiosammy/.local/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/fabiosammy/.local/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/fabiosammy/.local/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/fabiosammy/.local/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/fabiosammy/.local/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/fabiosammy/.local/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/fabiosammy/.local/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/fabiosammy/.local/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/fabiosammy/.local/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/fabiosammy/.local/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/fabiosammy/.local/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/fabiosammy/.local/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/fabiosammy/.local/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/fabiosammy/.local/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/fabiosammy/.local/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/fabiosammy/.local/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/fabiosammy/.local/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/fabiosammy/.local/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/fabiosammy/.local/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/fabiosammy/.local/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/fabiosammy/.local/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/fabiosammy/.local/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/fabiosammy/.local/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/fabiosammy/.local/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/fabiosammy/.local/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/fabiosammy/.local/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/fabiosammy/.local/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/fabiosammy/.local/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/fabiosammy/.local/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/fabiosammy/.local/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/fabiosammy/.local/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/fabiosammy/.local/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/fabiosammy/.local/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/fabiosammy/.local/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/fabiosammy/.local/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/fabiosammy/.local/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/fabiosammy/.local/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/fabiosammy/.local/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/fabiosammy/.local/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/fabiosammy/.local/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/fabiosammy/.local/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/fabiosammy/.local/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/fabiosammy/.local/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/fabiosammy/.local/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/fabiosammy/.local/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fabiosammy/.local/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/fabiosammy/.local/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/fabiosammy/.local/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/fabiosammy/.local/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/fabiosammy/.local/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "100%|█████████████████████████████████████████████| 6/6 [00:48<00:00,  8.03s/it]\n"
     ]
    }
   ],
   "source": [
    "execucoes = []\n",
    "kf = StratifiedKFold(n_splits=5, random_state=None, shuffle=False)\n",
    "k = 1\n",
    "i = 0\n",
    "for model in tqdm(modelos):\n",
    "    for i in range(10):\n",
    "        k = 1\n",
    "        clf = ModeloAuxiliar(clf=model['modelo'])\n",
    "        for indices_treino, indices_teste in kf.split(X_train, y_train):\n",
    "            k+=1 \n",
    "            X_Ttrain, X_Ttest = X[indices_treino], X[indices_teste]\n",
    "            y_Ttrain, y_Ttest = y[indices_treino], y[indices_teste]\n",
    "            clf.fit(X_Ttrain, y_Ttrain)\n",
    "            predicao_treino = clf.predict(X_Ttest)\n",
    "            precisao_teste = clf.predict(X_test)\n",
    "    # métricas de validacao\n",
    "            precision_treino = precision_score(y_Ttest,predicao_treino, average='binary', zero_division=0)*100 # Calculando a precisao\n",
    "            revocacao_treino =recall_score(y_Ttest, predicao_treino, average='binary', zero_division=0)*100 # Calcula a revocacao\n",
    "            acc_treino = accuracy_score(y_Ttest, predicao_treino)*100   # acuracia\n",
    "            \n",
    "            precision_teste = precision_score(y_test,precisao_teste, average='binary', zero_division=0)*100 # Calculando a precisao\n",
    "            revocacao_teste =recall_score(y_test, precisao_teste, average='binary', zero_division=0)*100 # Calcula a revocacao\n",
    "            acc_teste = accuracy_score(y_test, precisao_teste)*100   # acuracia\n",
    "            cm_teste = confusion_matrix(y_test, precisao_teste)\n",
    "    \n",
    "            execucoes.append({\n",
    "                        'Kfold':k,\n",
    "                        'nome': model['nome'],\n",
    "                        'acuracia_treino':acc_treino,\n",
    "                        'precisao_treino':precision_treino,\n",
    "                        'revocacao_treino':revocacao_treino,\n",
    "                        'acuracia_teste':acc_teste,\n",
    "                        'precisao_teste':precision_teste,\n",
    "                        'revocacao_teste':revocacao_teste,\n",
    "                        'cm': cm_teste\n",
    "                        })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "3f377c14",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(execucoes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "211846bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"ResultSIFTK5.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "16654390",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nome</th>\n",
       "      <th>acuracia_teste</th>\n",
       "      <th>precisao_teste</th>\n",
       "      <th>revocacao_teste</th>\n",
       "      <th>cm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Dtree</td>\n",
       "      <td>99.246575</td>\n",
       "      <td>98.446328</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>[[752, 11], [0, 697]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Dtree</td>\n",
       "      <td>99.246575</td>\n",
       "      <td>98.446328</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>[[752, 11], [0, 697]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Dtree</td>\n",
       "      <td>99.246575</td>\n",
       "      <td>98.446328</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>[[752, 11], [0, 697]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Dtree</td>\n",
       "      <td>99.246575</td>\n",
       "      <td>98.446328</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>[[752, 11], [0, 697]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Dtree</td>\n",
       "      <td>99.246575</td>\n",
       "      <td>98.446328</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>[[752, 11], [0, 697]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Dtree</td>\n",
       "      <td>99.246575</td>\n",
       "      <td>98.446328</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>[[752, 11], [0, 697]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>Dtree</td>\n",
       "      <td>99.246575</td>\n",
       "      <td>98.446328</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>[[752, 11], [0, 697]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>Dtree</td>\n",
       "      <td>99.246575</td>\n",
       "      <td>98.446328</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>[[752, 11], [0, 697]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>Dtree</td>\n",
       "      <td>99.246575</td>\n",
       "      <td>98.446328</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>[[752, 11], [0, 697]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>Dtree</td>\n",
       "      <td>99.246575</td>\n",
       "      <td>98.446328</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>[[752, 11], [0, 697]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>Knn</td>\n",
       "      <td>99.246575</td>\n",
       "      <td>98.446328</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>[[752, 11], [0, 697]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>Knn</td>\n",
       "      <td>99.246575</td>\n",
       "      <td>98.446328</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>[[752, 11], [0, 697]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>Knn</td>\n",
       "      <td>99.246575</td>\n",
       "      <td>98.446328</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>[[752, 11], [0, 697]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>Knn</td>\n",
       "      <td>99.246575</td>\n",
       "      <td>98.446328</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>[[752, 11], [0, 697]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>Knn</td>\n",
       "      <td>99.246575</td>\n",
       "      <td>98.446328</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>[[752, 11], [0, 697]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>Knn</td>\n",
       "      <td>99.246575</td>\n",
       "      <td>98.446328</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>[[752, 11], [0, 697]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>Knn</td>\n",
       "      <td>99.246575</td>\n",
       "      <td>98.446328</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>[[752, 11], [0, 697]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>Knn</td>\n",
       "      <td>99.246575</td>\n",
       "      <td>98.446328</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>[[752, 11], [0, 697]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>Knn</td>\n",
       "      <td>99.246575</td>\n",
       "      <td>98.446328</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>[[752, 11], [0, 697]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Knn</td>\n",
       "      <td>99.246575</td>\n",
       "      <td>98.446328</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>[[752, 11], [0, 697]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>Rfrorest</td>\n",
       "      <td>99.109589</td>\n",
       "      <td>98.169014</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>[[750, 13], [0, 697]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>Rfrorest</td>\n",
       "      <td>99.109589</td>\n",
       "      <td>98.169014</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>[[750, 13], [0, 697]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>Rfrorest</td>\n",
       "      <td>99.246575</td>\n",
       "      <td>98.446328</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>[[752, 11], [0, 697]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>Rfrorest</td>\n",
       "      <td>99.178082</td>\n",
       "      <td>98.307475</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>[[751, 12], [0, 697]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>Rfrorest</td>\n",
       "      <td>99.178082</td>\n",
       "      <td>98.307475</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>[[751, 12], [0, 697]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>Rfrorest</td>\n",
       "      <td>99.178082</td>\n",
       "      <td>98.307475</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>[[751, 12], [0, 697]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>Rfrorest</td>\n",
       "      <td>99.178082</td>\n",
       "      <td>98.307475</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>[[751, 12], [0, 697]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>Rfrorest</td>\n",
       "      <td>99.178082</td>\n",
       "      <td>98.307475</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>[[751, 12], [0, 697]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>Rfrorest</td>\n",
       "      <td>99.178082</td>\n",
       "      <td>98.307475</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>[[751, 12], [0, 697]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>Rfrorest</td>\n",
       "      <td>99.109589</td>\n",
       "      <td>98.169014</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>[[750, 13], [0, 697]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153</th>\n",
       "      <td>SGDClassifier</td>\n",
       "      <td>96.232877</td>\n",
       "      <td>93.852459</td>\n",
       "      <td>98.565280</td>\n",
       "      <td>[[718, 45], [10, 687]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>SGDClassifier</td>\n",
       "      <td>95.684932</td>\n",
       "      <td>92.379679</td>\n",
       "      <td>99.139168</td>\n",
       "      <td>[[706, 57], [6, 691]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163</th>\n",
       "      <td>SGDClassifier</td>\n",
       "      <td>92.876712</td>\n",
       "      <td>87.389660</td>\n",
       "      <td>99.426112</td>\n",
       "      <td>[[663, 100], [4, 693]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>SGDClassifier</td>\n",
       "      <td>95.753425</td>\n",
       "      <td>95.947902</td>\n",
       "      <td>95.121951</td>\n",
       "      <td>[[735, 28], [34, 663]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>SGDClassifier</td>\n",
       "      <td>80.479452</td>\n",
       "      <td>70.977597</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>[[478, 285], [0, 697]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178</th>\n",
       "      <td>SGDClassifier</td>\n",
       "      <td>96.095890</td>\n",
       "      <td>93.956044</td>\n",
       "      <td>98.134864</td>\n",
       "      <td>[[719, 44], [13, 684]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183</th>\n",
       "      <td>SGDClassifier</td>\n",
       "      <td>95.958904</td>\n",
       "      <td>94.182825</td>\n",
       "      <td>97.560976</td>\n",
       "      <td>[[721, 42], [17, 680]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188</th>\n",
       "      <td>SGDClassifier</td>\n",
       "      <td>96.095890</td>\n",
       "      <td>94.817927</td>\n",
       "      <td>97.130560</td>\n",
       "      <td>[[726, 37], [20, 677]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>SGDClassifier</td>\n",
       "      <td>93.767123</td>\n",
       "      <td>88.946015</td>\n",
       "      <td>99.282640</td>\n",
       "      <td>[[677, 86], [5, 692]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>SGDClassifier</td>\n",
       "      <td>85.068493</td>\n",
       "      <td>76.174863</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>[[545, 218], [0, 697]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203</th>\n",
       "      <td>SVC</td>\n",
       "      <td>99.178082</td>\n",
       "      <td>98.307475</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>[[751, 12], [0, 697]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>208</th>\n",
       "      <td>SVC</td>\n",
       "      <td>99.178082</td>\n",
       "      <td>98.307475</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>[[751, 12], [0, 697]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>213</th>\n",
       "      <td>SVC</td>\n",
       "      <td>99.178082</td>\n",
       "      <td>98.307475</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>[[751, 12], [0, 697]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>218</th>\n",
       "      <td>SVC</td>\n",
       "      <td>99.178082</td>\n",
       "      <td>98.307475</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>[[751, 12], [0, 697]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223</th>\n",
       "      <td>SVC</td>\n",
       "      <td>99.178082</td>\n",
       "      <td>98.307475</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>[[751, 12], [0, 697]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>228</th>\n",
       "      <td>SVC</td>\n",
       "      <td>99.178082</td>\n",
       "      <td>98.307475</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>[[751, 12], [0, 697]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>233</th>\n",
       "      <td>SVC</td>\n",
       "      <td>99.178082</td>\n",
       "      <td>98.307475</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>[[751, 12], [0, 697]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238</th>\n",
       "      <td>SVC</td>\n",
       "      <td>99.178082</td>\n",
       "      <td>98.307475</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>[[751, 12], [0, 697]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>243</th>\n",
       "      <td>SVC</td>\n",
       "      <td>99.178082</td>\n",
       "      <td>98.307475</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>[[751, 12], [0, 697]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>248</th>\n",
       "      <td>SVC</td>\n",
       "      <td>99.178082</td>\n",
       "      <td>98.307475</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>[[751, 12], [0, 697]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>253</th>\n",
       "      <td>LinearSVC</td>\n",
       "      <td>89.794521</td>\n",
       "      <td>82.387707</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>[[614, 149], [0, 697]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>258</th>\n",
       "      <td>LinearSVC</td>\n",
       "      <td>92.397260</td>\n",
       "      <td>86.262376</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>[[652, 111], [0, 697]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>263</th>\n",
       "      <td>LinearSVC</td>\n",
       "      <td>96.986301</td>\n",
       "      <td>96.576320</td>\n",
       "      <td>97.130560</td>\n",
       "      <td>[[739, 24], [20, 677]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>268</th>\n",
       "      <td>LinearSVC</td>\n",
       "      <td>96.506849</td>\n",
       "      <td>94.368132</td>\n",
       "      <td>98.565280</td>\n",
       "      <td>[[722, 41], [10, 687]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>273</th>\n",
       "      <td>LinearSVC</td>\n",
       "      <td>96.438356</td>\n",
       "      <td>94.238683</td>\n",
       "      <td>98.565280</td>\n",
       "      <td>[[721, 42], [10, 687]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>278</th>\n",
       "      <td>LinearSVC</td>\n",
       "      <td>96.986301</td>\n",
       "      <td>96.443812</td>\n",
       "      <td>97.274032</td>\n",
       "      <td>[[738, 25], [19, 678]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>283</th>\n",
       "      <td>LinearSVC</td>\n",
       "      <td>96.849315</td>\n",
       "      <td>97.518248</td>\n",
       "      <td>95.839311</td>\n",
       "      <td>[[746, 17], [29, 668]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>288</th>\n",
       "      <td>LinearSVC</td>\n",
       "      <td>96.095890</td>\n",
       "      <td>93.478261</td>\n",
       "      <td>98.708752</td>\n",
       "      <td>[[715, 48], [9, 688]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>293</th>\n",
       "      <td>LinearSVC</td>\n",
       "      <td>96.506849</td>\n",
       "      <td>94.490358</td>\n",
       "      <td>98.421808</td>\n",
       "      <td>[[723, 40], [11, 686]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>LinearSVC</td>\n",
       "      <td>96.506849</td>\n",
       "      <td>98.065476</td>\n",
       "      <td>94.548063</td>\n",
       "      <td>[[750, 13], [38, 659]]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              nome  acuracia_teste  precisao_teste  revocacao_teste   \n",
       "3            Dtree       99.246575       98.446328       100.000000  \\\n",
       "8            Dtree       99.246575       98.446328       100.000000   \n",
       "13           Dtree       99.246575       98.446328       100.000000   \n",
       "18           Dtree       99.246575       98.446328       100.000000   \n",
       "23           Dtree       99.246575       98.446328       100.000000   \n",
       "28           Dtree       99.246575       98.446328       100.000000   \n",
       "33           Dtree       99.246575       98.446328       100.000000   \n",
       "38           Dtree       99.246575       98.446328       100.000000   \n",
       "43           Dtree       99.246575       98.446328       100.000000   \n",
       "48           Dtree       99.246575       98.446328       100.000000   \n",
       "53             Knn       99.246575       98.446328       100.000000   \n",
       "58             Knn       99.246575       98.446328       100.000000   \n",
       "63             Knn       99.246575       98.446328       100.000000   \n",
       "68             Knn       99.246575       98.446328       100.000000   \n",
       "73             Knn       99.246575       98.446328       100.000000   \n",
       "78             Knn       99.246575       98.446328       100.000000   \n",
       "83             Knn       99.246575       98.446328       100.000000   \n",
       "88             Knn       99.246575       98.446328       100.000000   \n",
       "93             Knn       99.246575       98.446328       100.000000   \n",
       "98             Knn       99.246575       98.446328       100.000000   \n",
       "103       Rfrorest       99.109589       98.169014       100.000000   \n",
       "108       Rfrorest       99.109589       98.169014       100.000000   \n",
       "113       Rfrorest       99.246575       98.446328       100.000000   \n",
       "118       Rfrorest       99.178082       98.307475       100.000000   \n",
       "123       Rfrorest       99.178082       98.307475       100.000000   \n",
       "128       Rfrorest       99.178082       98.307475       100.000000   \n",
       "133       Rfrorest       99.178082       98.307475       100.000000   \n",
       "138       Rfrorest       99.178082       98.307475       100.000000   \n",
       "143       Rfrorest       99.178082       98.307475       100.000000   \n",
       "148       Rfrorest       99.109589       98.169014       100.000000   \n",
       "153  SGDClassifier       96.232877       93.852459        98.565280   \n",
       "158  SGDClassifier       95.684932       92.379679        99.139168   \n",
       "163  SGDClassifier       92.876712       87.389660        99.426112   \n",
       "168  SGDClassifier       95.753425       95.947902        95.121951   \n",
       "173  SGDClassifier       80.479452       70.977597       100.000000   \n",
       "178  SGDClassifier       96.095890       93.956044        98.134864   \n",
       "183  SGDClassifier       95.958904       94.182825        97.560976   \n",
       "188  SGDClassifier       96.095890       94.817927        97.130560   \n",
       "193  SGDClassifier       93.767123       88.946015        99.282640   \n",
       "198  SGDClassifier       85.068493       76.174863       100.000000   \n",
       "203            SVC       99.178082       98.307475       100.000000   \n",
       "208            SVC       99.178082       98.307475       100.000000   \n",
       "213            SVC       99.178082       98.307475       100.000000   \n",
       "218            SVC       99.178082       98.307475       100.000000   \n",
       "223            SVC       99.178082       98.307475       100.000000   \n",
       "228            SVC       99.178082       98.307475       100.000000   \n",
       "233            SVC       99.178082       98.307475       100.000000   \n",
       "238            SVC       99.178082       98.307475       100.000000   \n",
       "243            SVC       99.178082       98.307475       100.000000   \n",
       "248            SVC       99.178082       98.307475       100.000000   \n",
       "253      LinearSVC       89.794521       82.387707       100.000000   \n",
       "258      LinearSVC       92.397260       86.262376       100.000000   \n",
       "263      LinearSVC       96.986301       96.576320        97.130560   \n",
       "268      LinearSVC       96.506849       94.368132        98.565280   \n",
       "273      LinearSVC       96.438356       94.238683        98.565280   \n",
       "278      LinearSVC       96.986301       96.443812        97.274032   \n",
       "283      LinearSVC       96.849315       97.518248        95.839311   \n",
       "288      LinearSVC       96.095890       93.478261        98.708752   \n",
       "293      LinearSVC       96.506849       94.490358        98.421808   \n",
       "298      LinearSVC       96.506849       98.065476        94.548063   \n",
       "\n",
       "                         cm  \n",
       "3     [[752, 11], [0, 697]]  \n",
       "8     [[752, 11], [0, 697]]  \n",
       "13    [[752, 11], [0, 697]]  \n",
       "18    [[752, 11], [0, 697]]  \n",
       "23    [[752, 11], [0, 697]]  \n",
       "28    [[752, 11], [0, 697]]  \n",
       "33    [[752, 11], [0, 697]]  \n",
       "38    [[752, 11], [0, 697]]  \n",
       "43    [[752, 11], [0, 697]]  \n",
       "48    [[752, 11], [0, 697]]  \n",
       "53    [[752, 11], [0, 697]]  \n",
       "58    [[752, 11], [0, 697]]  \n",
       "63    [[752, 11], [0, 697]]  \n",
       "68    [[752, 11], [0, 697]]  \n",
       "73    [[752, 11], [0, 697]]  \n",
       "78    [[752, 11], [0, 697]]  \n",
       "83    [[752, 11], [0, 697]]  \n",
       "88    [[752, 11], [0, 697]]  \n",
       "93    [[752, 11], [0, 697]]  \n",
       "98    [[752, 11], [0, 697]]  \n",
       "103   [[750, 13], [0, 697]]  \n",
       "108   [[750, 13], [0, 697]]  \n",
       "113   [[752, 11], [0, 697]]  \n",
       "118   [[751, 12], [0, 697]]  \n",
       "123   [[751, 12], [0, 697]]  \n",
       "128   [[751, 12], [0, 697]]  \n",
       "133   [[751, 12], [0, 697]]  \n",
       "138   [[751, 12], [0, 697]]  \n",
       "143   [[751, 12], [0, 697]]  \n",
       "148   [[750, 13], [0, 697]]  \n",
       "153  [[718, 45], [10, 687]]  \n",
       "158   [[706, 57], [6, 691]]  \n",
       "163  [[663, 100], [4, 693]]  \n",
       "168  [[735, 28], [34, 663]]  \n",
       "173  [[478, 285], [0, 697]]  \n",
       "178  [[719, 44], [13, 684]]  \n",
       "183  [[721, 42], [17, 680]]  \n",
       "188  [[726, 37], [20, 677]]  \n",
       "193   [[677, 86], [5, 692]]  \n",
       "198  [[545, 218], [0, 697]]  \n",
       "203   [[751, 12], [0, 697]]  \n",
       "208   [[751, 12], [0, 697]]  \n",
       "213   [[751, 12], [0, 697]]  \n",
       "218   [[751, 12], [0, 697]]  \n",
       "223   [[751, 12], [0, 697]]  \n",
       "228   [[751, 12], [0, 697]]  \n",
       "233   [[751, 12], [0, 697]]  \n",
       "238   [[751, 12], [0, 697]]  \n",
       "243   [[751, 12], [0, 697]]  \n",
       "248   [[751, 12], [0, 697]]  \n",
       "253  [[614, 149], [0, 697]]  \n",
       "258  [[652, 111], [0, 697]]  \n",
       "263  [[739, 24], [20, 677]]  \n",
       "268  [[722, 41], [10, 687]]  \n",
       "273  [[721, 42], [10, 687]]  \n",
       "278  [[738, 25], [19, 678]]  \n",
       "283  [[746, 17], [29, 668]]  \n",
       "288   [[715, 48], [9, 688]]  \n",
       "293  [[723, 40], [11, 686]]  \n",
       "298  [[750, 13], [38, 659]]  "
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[['nome','acuracia_teste', 'precisao_teste', 'revocacao_teste', 'cm']].loc[df['Kfold']==5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "bdddcc65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>acuracia_teste</th>\n",
       "      <th>precisao_teste</th>\n",
       "      <th>revocacao_teste</th>\n",
       "      <th>cm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>99.246575</td>\n",
       "      <td>98.446328</td>\n",
       "      <td>100.0</td>\n",
       "      <td>[[752, 11], [0, 697]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>99.246575</td>\n",
       "      <td>98.446328</td>\n",
       "      <td>100.0</td>\n",
       "      <td>[[752, 11], [0, 697]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>99.246575</td>\n",
       "      <td>98.446328</td>\n",
       "      <td>100.0</td>\n",
       "      <td>[[752, 11], [0, 697]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>99.246575</td>\n",
       "      <td>98.446328</td>\n",
       "      <td>100.0</td>\n",
       "      <td>[[752, 11], [0, 697]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>99.246575</td>\n",
       "      <td>98.446328</td>\n",
       "      <td>100.0</td>\n",
       "      <td>[[752, 11], [0, 697]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>99.246575</td>\n",
       "      <td>98.446328</td>\n",
       "      <td>100.0</td>\n",
       "      <td>[[752, 11], [0, 697]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>99.246575</td>\n",
       "      <td>98.446328</td>\n",
       "      <td>100.0</td>\n",
       "      <td>[[752, 11], [0, 697]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>99.246575</td>\n",
       "      <td>98.446328</td>\n",
       "      <td>100.0</td>\n",
       "      <td>[[752, 11], [0, 697]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>99.246575</td>\n",
       "      <td>98.446328</td>\n",
       "      <td>100.0</td>\n",
       "      <td>[[752, 11], [0, 697]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>99.246575</td>\n",
       "      <td>98.446328</td>\n",
       "      <td>100.0</td>\n",
       "      <td>[[752, 11], [0, 697]]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    acuracia_teste  precisao_teste  revocacao_teste                     cm\n",
       "3        99.246575       98.446328            100.0  [[752, 11], [0, 697]]\n",
       "8        99.246575       98.446328            100.0  [[752, 11], [0, 697]]\n",
       "13       99.246575       98.446328            100.0  [[752, 11], [0, 697]]\n",
       "18       99.246575       98.446328            100.0  [[752, 11], [0, 697]]\n",
       "23       99.246575       98.446328            100.0  [[752, 11], [0, 697]]\n",
       "28       99.246575       98.446328            100.0  [[752, 11], [0, 697]]\n",
       "33       99.246575       98.446328            100.0  [[752, 11], [0, 697]]\n",
       "38       99.246575       98.446328            100.0  [[752, 11], [0, 697]]\n",
       "43       99.246575       98.446328            100.0  [[752, 11], [0, 697]]\n",
       "48       99.246575       98.446328            100.0  [[752, 11], [0, 697]]"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[['acuracia_teste', 'precisao_teste', 'revocacao_teste', 'cm']].loc[(df['Kfold']==5) & (df['nome']=='Dtree')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "7a714d5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "acuracia_teste      99.246575\n",
       "precisao_teste      98.446328\n",
       "revocacao_teste    100.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[['acuracia_teste', 'precisao_teste', 'revocacao_teste']].loc[(df['Kfold']==5) & (df['nome']=='Knn')].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "34c82049",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "acuracia_teste      99.164384\n",
       "precisao_teste      98.279822\n",
       "revocacao_teste    100.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[['acuracia_teste', 'precisao_teste', 'revocacao_teste']].loc[(df['Kfold']==5) & (df['nome']=='Rfrorest')].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "5d926562",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "acuracia_teste      99.178082\n",
       "precisao_teste      98.307475\n",
       "revocacao_teste    100.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[['acuracia_teste', 'precisao_teste', 'revocacao_teste']].loc[(df['Kfold']==5) & (df['nome']=='SVC')].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "b7926eac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "acuracia_teste     95.506849\n",
       "precisao_teste     93.382937\n",
       "revocacao_teste    97.905308\n",
       "dtype: float64"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[['acuracia_teste', 'precisao_teste', 'revocacao_teste']].loc[(df['Kfold']==5) & (df['nome']=='LinearSVC')].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "9464d6b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "acuracia_teste     92.801370\n",
       "precisao_teste     88.862497\n",
       "revocacao_teste    98.436155\n",
       "dtype: float64"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[['acuracia_teste', 'precisao_teste', 'revocacao_teste']].loc[(df['Kfold']==5) & (df['nome']=='SGDClassifier')].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8a59fdc",
   "metadata": {},
   "source": [
    "## Avaliando com Kfolds=10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "8a52e837",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|█████████████████████████████████████▌       | 5/6 [01:11<00:13, 13.96s/it]/home/fabiosammy/.local/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/fabiosammy/.local/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/fabiosammy/.local/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/fabiosammy/.local/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/fabiosammy/.local/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/fabiosammy/.local/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/fabiosammy/.local/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/fabiosammy/.local/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/fabiosammy/.local/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/fabiosammy/.local/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/fabiosammy/.local/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/fabiosammy/.local/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/fabiosammy/.local/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/fabiosammy/.local/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/fabiosammy/.local/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/fabiosammy/.local/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/fabiosammy/.local/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/fabiosammy/.local/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/fabiosammy/.local/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/fabiosammy/.local/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/fabiosammy/.local/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/fabiosammy/.local/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/fabiosammy/.local/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/fabiosammy/.local/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/fabiosammy/.local/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/fabiosammy/.local/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/fabiosammy/.local/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/fabiosammy/.local/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/fabiosammy/.local/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/fabiosammy/.local/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/fabiosammy/.local/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/fabiosammy/.local/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/fabiosammy/.local/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/fabiosammy/.local/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/fabiosammy/.local/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/fabiosammy/.local/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/fabiosammy/.local/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/fabiosammy/.local/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/fabiosammy/.local/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/fabiosammy/.local/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/fabiosammy/.local/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/fabiosammy/.local/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/fabiosammy/.local/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/fabiosammy/.local/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/fabiosammy/.local/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fabiosammy/.local/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/fabiosammy/.local/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/fabiosammy/.local/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/fabiosammy/.local/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/fabiosammy/.local/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/fabiosammy/.local/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/fabiosammy/.local/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/fabiosammy/.local/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/fabiosammy/.local/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/fabiosammy/.local/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/fabiosammy/.local/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/fabiosammy/.local/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/fabiosammy/.local/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/fabiosammy/.local/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/fabiosammy/.local/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/fabiosammy/.local/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/fabiosammy/.local/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/fabiosammy/.local/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/fabiosammy/.local/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/fabiosammy/.local/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/fabiosammy/.local/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/fabiosammy/.local/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/fabiosammy/.local/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/fabiosammy/.local/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/fabiosammy/.local/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/fabiosammy/.local/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/fabiosammy/.local/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/fabiosammy/.local/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/fabiosammy/.local/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/fabiosammy/.local/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/fabiosammy/.local/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/fabiosammy/.local/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/fabiosammy/.local/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/fabiosammy/.local/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/fabiosammy/.local/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/fabiosammy/.local/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/fabiosammy/.local/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/fabiosammy/.local/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/fabiosammy/.local/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/fabiosammy/.local/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/fabiosammy/.local/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/fabiosammy/.local/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/fabiosammy/.local/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/fabiosammy/.local/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/fabiosammy/.local/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/fabiosammy/.local/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fabiosammy/.local/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/fabiosammy/.local/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/fabiosammy/.local/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/fabiosammy/.local/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/fabiosammy/.local/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/fabiosammy/.local/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/fabiosammy/.local/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/fabiosammy/.local/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/fabiosammy/.local/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "100%|█████████████████████████████████████████████| 6/6 [01:43<00:00, 17.20s/it]\n"
     ]
    }
   ],
   "source": [
    "execucoes = []\n",
    "kf = StratifiedKFold(n_splits=10, random_state=None, shuffle=False)\n",
    "k = 0\n",
    "i = 0\n",
    "for model in tqdm(modelos):\n",
    "    for i in range(10):\n",
    "        k = 1\n",
    "        clf = ModeloAuxiliar(clf=model['modelo'])\n",
    "        for indices_treino, indices_teste in kf.split(X_train, y_train):\n",
    "            k+=1 \n",
    "            X_Ttrain, X_Ttest = X[indices_treino], X[indices_teste]\n",
    "            y_Ttrain, y_Ttest = y[indices_treino], y[indices_teste]\n",
    "            clf.fit(X_Ttrain, y_Ttrain)\n",
    "            predicao_treino = clf.predict(X_Ttest)\n",
    "            precisao_teste = clf.predict(X_test)\n",
    "    # métricas de validacao\n",
    "            precision_treino = precision_score(y_Ttest,predicao_treino, average='binary', zero_division=0)*100 # Calculando a precisao\n",
    "            revocacao_treino =recall_score(y_Ttest, predicao_treino, average='binary', zero_division=0)*100 # Calcula a revocacao\n",
    "            acc_treino = accuracy_score(y_Ttest, predicao_treino)*100   # acuracia\n",
    "            \n",
    "            precision_teste = precision_score(y_test,precisao_teste, average='binary', zero_division=0)*100 # Calculando a precisao\n",
    "            revocacao_teste =recall_score(y_test, precisao_teste, average='binary', zero_division=0)*100 # Calcula a revocacao\n",
    "            acc_teste = accuracy_score(y_test, precisao_teste)*100   # acuracia\n",
    "            cm_teste = confusion_matrix(y_test, precisao_teste)\n",
    "    \n",
    "            execucoes.append({\n",
    "                        'Kfold':k,\n",
    "                        'nome': model['nome'],\n",
    "                        'acuracia_treino':acc_treino,\n",
    "                        'precisao_treino':precision_treino,\n",
    "                        'revocacao_treino':revocacao_treino,\n",
    "                        'acuracia_teste':acc_teste,\n",
    "                        'precisao_teste':precision_teste,\n",
    "                        'revocacao_teste':revocacao_teste,\n",
    "                        'cm': cm_teste\n",
    "                        })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "f011a2c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Kfold</th>\n",
       "      <th>nome</th>\n",
       "      <th>acuracia_treino</th>\n",
       "      <th>precisao_treino</th>\n",
       "      <th>revocacao_treino</th>\n",
       "      <th>acuracia_teste</th>\n",
       "      <th>precisao_teste</th>\n",
       "      <th>revocacao_teste</th>\n",
       "      <th>cm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>Dtree</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>[[763, 0], [0, 697]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>Dtree</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>[[763, 0], [0, 697]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>Dtree</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>[[763, 0], [0, 697]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>Dtree</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>[[763, 0], [0, 697]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>Dtree</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>[[763, 0], [0, 697]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>595</th>\n",
       "      <td>7</td>\n",
       "      <td>LinearSVC</td>\n",
       "      <td>98.823529</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>87.328767</td>\n",
       "      <td>99.805447</td>\n",
       "      <td>73.601148</td>\n",
       "      <td>[[762, 1], [184, 513]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>596</th>\n",
       "      <td>8</td>\n",
       "      <td>LinearSVC</td>\n",
       "      <td>75.294118</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>96.506849</td>\n",
       "      <td>93.885870</td>\n",
       "      <td>99.139168</td>\n",
       "      <td>[[718, 45], [6, 691]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>597</th>\n",
       "      <td>9</td>\n",
       "      <td>LinearSVC</td>\n",
       "      <td>83.235294</td>\n",
       "      <td>94.676806</td>\n",
       "      <td>85.273973</td>\n",
       "      <td>97.123288</td>\n",
       "      <td>97.950220</td>\n",
       "      <td>95.982783</td>\n",
       "      <td>[[749, 14], [28, 669]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>598</th>\n",
       "      <td>10</td>\n",
       "      <td>LinearSVC</td>\n",
       "      <td>85.294118</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>85.294118</td>\n",
       "      <td>95.136986</td>\n",
       "      <td>99.369085</td>\n",
       "      <td>90.387374</td>\n",
       "      <td>[[759, 4], [67, 630]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>599</th>\n",
       "      <td>11</td>\n",
       "      <td>LinearSVC</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>96.232877</td>\n",
       "      <td>93.378378</td>\n",
       "      <td>99.139168</td>\n",
       "      <td>[[714, 49], [6, 691]]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>600 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Kfold       nome  acuracia_treino  precisao_treino  revocacao_treino   \n",
       "0        2      Dtree       100.000000         0.000000          0.000000  \\\n",
       "1        3      Dtree       100.000000         0.000000          0.000000   \n",
       "2        4      Dtree       100.000000         0.000000          0.000000   \n",
       "3        5      Dtree       100.000000         0.000000          0.000000   \n",
       "4        6      Dtree       100.000000         0.000000          0.000000   \n",
       "..     ...        ...              ...              ...               ...   \n",
       "595      7  LinearSVC        98.823529         0.000000          0.000000   \n",
       "596      8  LinearSVC        75.294118         0.000000          0.000000   \n",
       "597      9  LinearSVC        83.235294        94.676806         85.273973   \n",
       "598     10  LinearSVC        85.294118       100.000000         85.294118   \n",
       "599     11  LinearSVC       100.000000       100.000000        100.000000   \n",
       "\n",
       "     acuracia_teste  precisao_teste  revocacao_teste                      cm  \n",
       "0        100.000000      100.000000       100.000000    [[763, 0], [0, 697]]  \n",
       "1        100.000000      100.000000       100.000000    [[763, 0], [0, 697]]  \n",
       "2        100.000000      100.000000       100.000000    [[763, 0], [0, 697]]  \n",
       "3        100.000000      100.000000       100.000000    [[763, 0], [0, 697]]  \n",
       "4        100.000000      100.000000       100.000000    [[763, 0], [0, 697]]  \n",
       "..              ...             ...              ...                     ...  \n",
       "595       87.328767       99.805447        73.601148  [[762, 1], [184, 513]]  \n",
       "596       96.506849       93.885870        99.139168   [[718, 45], [6, 691]]  \n",
       "597       97.123288       97.950220        95.982783  [[749, 14], [28, 669]]  \n",
       "598       95.136986       99.369085        90.387374   [[759, 4], [67, 630]]  \n",
       "599       96.232877       93.378378        99.139168   [[714, 49], [6, 691]]  \n",
       "\n",
       "[600 rows x 9 columns]"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1 = pd.DataFrame(execucoes)\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "0364a5ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "acuracia_teste     100.0\n",
       "precisao_teste     100.0\n",
       "revocacao_teste    100.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1[['acuracia_teste', 'precisao_teste', 'revocacao_teste']].loc[(df1['Kfold']==10) & (df1['nome']=='Dtree')].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "d1c2be54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "acuracia_teste      99.931507\n",
       "precisao_teste      99.856734\n",
       "revocacao_teste    100.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1[['acuracia_teste', 'precisao_teste', 'revocacao_teste']].loc[(df1['Kfold']==10) & (df1['nome']=='Knn')].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "1e47ad2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "acuracia_teste     100.0\n",
       "precisao_teste     100.0\n",
       "revocacao_teste    100.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1[['acuracia_teste', 'precisao_teste', 'revocacao_teste']].loc[(df1['Kfold']==10) & (df1['nome']=='SVC')].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "b2991b69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "acuracia_teste     100.0\n",
       "precisao_teste     100.0\n",
       "revocacao_teste    100.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1[['acuracia_teste', 'precisao_teste', 'revocacao_teste']].loc[(df1['Kfold']==10) & (df1['nome']=='Rfrorest')].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "32c1cdb6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "acuracia_teste     94.383562\n",
       "precisao_teste     96.809591\n",
       "revocacao_teste    91.549498\n",
       "dtype: float64"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1[['acuracia_teste', 'precisao_teste', 'revocacao_teste']].loc[(df1['Kfold']==5) & (df1['nome']=='LinearSVC')].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "a8746e65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "acuracia_teste     91.589041\n",
       "precisao_teste     92.824195\n",
       "revocacao_teste    90.746055\n",
       "dtype: float64"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1[['acuracia_teste', 'precisao_teste', 'revocacao_teste']].loc[(df1['Kfold']==5) & (df1['nome']=='SGDClassifier')].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54936501",
   "metadata": {},
   "source": [
    "## Fazendo o teste de posthoc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "4ade72bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scikit_posthocs as sp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "212548ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = pd.DataFrame({\"DT\":[99.24,99.24,99.24,99.24,99.24,99.24,99.24,99.24,99.24,99.24],\n",
    "\"Knn\":[99.24,99.24,99.24,99.24,99.24,99.24,99.24,99.24,99.24,99.24],\n",
    "\"RF\":[99.10,99.10,99.24,99.17,99.17,99.17,99.17,99.17,99.17,99.10],\n",
    "\"SVM\":[96.23,95.68,92.87,95.75,80.47,96.09,95.95,96.09,96.76,85.06],\n",
    "\"LinearSVM\":[99.17,99.17,99.17,99.17,99.17,99.17,99.17,99.17,99.17,99.17],\n",
    "\"SGD\":[89.79,92.39,96.98,96.50,96.43,96.98,96.84,96.09,96.50,96.50]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "a3d582df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>groups</th>\n",
       "      <th>vals</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DT</td>\n",
       "      <td>99.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DT</td>\n",
       "      <td>99.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DT</td>\n",
       "      <td>99.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DT</td>\n",
       "      <td>99.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DT</td>\n",
       "      <td>99.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>DT</td>\n",
       "      <td>99.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>DT</td>\n",
       "      <td>99.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>DT</td>\n",
       "      <td>99.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>DT</td>\n",
       "      <td>99.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>DT</td>\n",
       "      <td>99.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Knn</td>\n",
       "      <td>99.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Knn</td>\n",
       "      <td>99.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Knn</td>\n",
       "      <td>99.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Knn</td>\n",
       "      <td>99.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Knn</td>\n",
       "      <td>99.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Knn</td>\n",
       "      <td>99.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Knn</td>\n",
       "      <td>99.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Knn</td>\n",
       "      <td>99.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Knn</td>\n",
       "      <td>99.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Knn</td>\n",
       "      <td>99.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>RF</td>\n",
       "      <td>99.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>RF</td>\n",
       "      <td>99.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>RF</td>\n",
       "      <td>99.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>RF</td>\n",
       "      <td>99.17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>RF</td>\n",
       "      <td>99.17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>RF</td>\n",
       "      <td>99.17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>RF</td>\n",
       "      <td>99.17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>RF</td>\n",
       "      <td>99.17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>RF</td>\n",
       "      <td>99.17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>RF</td>\n",
       "      <td>99.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>SVM</td>\n",
       "      <td>96.23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>SVM</td>\n",
       "      <td>95.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>SVM</td>\n",
       "      <td>92.87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>SVM</td>\n",
       "      <td>95.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>SVM</td>\n",
       "      <td>80.47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>SVM</td>\n",
       "      <td>96.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>SVM</td>\n",
       "      <td>95.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>SVM</td>\n",
       "      <td>96.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>SVM</td>\n",
       "      <td>96.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>SVM</td>\n",
       "      <td>85.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>LinearSVM</td>\n",
       "      <td>99.17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>LinearSVM</td>\n",
       "      <td>99.17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>LinearSVM</td>\n",
       "      <td>99.17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>LinearSVM</td>\n",
       "      <td>99.17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>LinearSVM</td>\n",
       "      <td>99.17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>LinearSVM</td>\n",
       "      <td>99.17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>LinearSVM</td>\n",
       "      <td>99.17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>LinearSVM</td>\n",
       "      <td>99.17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>LinearSVM</td>\n",
       "      <td>99.17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>LinearSVM</td>\n",
       "      <td>99.17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>SGD</td>\n",
       "      <td>89.79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>SGD</td>\n",
       "      <td>92.39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>SGD</td>\n",
       "      <td>96.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>SGD</td>\n",
       "      <td>96.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>SGD</td>\n",
       "      <td>96.43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>SGD</td>\n",
       "      <td>96.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>SGD</td>\n",
       "      <td>96.84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>SGD</td>\n",
       "      <td>96.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>SGD</td>\n",
       "      <td>96.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>SGD</td>\n",
       "      <td>96.50</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       groups   vals\n",
       "0          DT  99.24\n",
       "1          DT  99.24\n",
       "2          DT  99.24\n",
       "3          DT  99.24\n",
       "4          DT  99.24\n",
       "5          DT  99.24\n",
       "6          DT  99.24\n",
       "7          DT  99.24\n",
       "8          DT  99.24\n",
       "9          DT  99.24\n",
       "10        Knn  99.24\n",
       "11        Knn  99.24\n",
       "12        Knn  99.24\n",
       "13        Knn  99.24\n",
       "14        Knn  99.24\n",
       "15        Knn  99.24\n",
       "16        Knn  99.24\n",
       "17        Knn  99.24\n",
       "18        Knn  99.24\n",
       "19        Knn  99.24\n",
       "20         RF  99.10\n",
       "21         RF  99.10\n",
       "22         RF  99.24\n",
       "23         RF  99.17\n",
       "24         RF  99.17\n",
       "25         RF  99.17\n",
       "26         RF  99.17\n",
       "27         RF  99.17\n",
       "28         RF  99.17\n",
       "29         RF  99.10\n",
       "30        SVM  96.23\n",
       "31        SVM  95.68\n",
       "32        SVM  92.87\n",
       "33        SVM  95.75\n",
       "34        SVM  80.47\n",
       "35        SVM  96.09\n",
       "36        SVM  95.95\n",
       "37        SVM  96.09\n",
       "38        SVM  96.76\n",
       "39        SVM  85.06\n",
       "40  LinearSVM  99.17\n",
       "41  LinearSVM  99.17\n",
       "42  LinearSVM  99.17\n",
       "43  LinearSVM  99.17\n",
       "44  LinearSVM  99.17\n",
       "45  LinearSVM  99.17\n",
       "46  LinearSVM  99.17\n",
       "47  LinearSVM  99.17\n",
       "48  LinearSVM  99.17\n",
       "49  LinearSVM  99.17\n",
       "50        SGD  89.79\n",
       "51        SGD  92.39\n",
       "52        SGD  96.98\n",
       "53        SGD  96.50\n",
       "54        SGD  96.43\n",
       "55        SGD  96.98\n",
       "56        SGD  96.84\n",
       "57        SGD  96.09\n",
       "58        SGD  96.50\n",
       "59        SGD  96.50"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = x.melt(var_name='groups', value_name='vals')\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "75b168c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#post = sp.__convert_to_df(x)\n",
    "pc = sp.posthoc_conover(x, val_col='vals', group_col='groups')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "e7907e5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<Axes: >, <matplotlib.colorbar.Colorbar at 0x7f496a1572e0>)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "heatmap_args = {'linewidths':0.25, 'linecolor':'0.5', 'clip_on':False, 'square':True, 'cbar_ax_bbox':[0.80, 0.35, 0.04, 0.3]}\n",
    "sp.sign_plot(pc, **heatmap_args)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
